{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data before cleaning: \n",
      "Avatar\n",
      "[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}]\n",
      "In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, but becomes torn between following orders and protecting an alien civilization. \n",
      "\n",
      "\n",
      "Data after cleaning: \n",
      "Avatar\n",
      "['Action', 'Adventure', 'Fantasy', 'Science Fiction']\n",
      "['22nd', 'century', 'paraplegic', 'Marine', 'dispatched', 'moon', 'Pandora', 'unique', 'mission', 'becomes', 'torn', 'between', 'following', 'orders', 'protecting', 'alien', 'civilization'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First we need to import some packages\n",
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Now read in the data\n",
    "data=pd.read_csv('./tmdb_5000_movies.csv')\n",
    "\n",
    "# Change data and get only what we want\n",
    "data=data[['title','genres','overview']]\n",
    "\n",
    "# Print out the first record\n",
    "print(\"Data before cleaning: \")\n",
    "print(data['title'][0])\n",
    "print(data['genres'][0])\n",
    "print(data['overview'][0], \"\\n\\n\")\n",
    "\n",
    "# define a function to clean our genres from [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}]\n",
    "# to [Action, Aventure, Fantasy, Science Fiction]\n",
    "def clean_genres(genre_data):\n",
    "    # List to hold results\n",
    "    genre_list = []\n",
    "    for item in genre_data:\n",
    "        # Since data is json we can use the json lib\n",
    "        json_data = json.loads(item)\n",
    "        temp_list = []\n",
    "\n",
    "        for dict_item in json_data:\n",
    "            # Grab only the genre names\n",
    "            temp_list.append(dict_item[\"name\"])\n",
    "    \n",
    "        genre_list.append(temp_list)\n",
    "\n",
    "    return genre_list\n",
    "\n",
    "def clean_overview(overview_list):\n",
    "    # List of words to remove\n",
    "    words_to_remove = [\"a\", \"and\", \"the\", \"but\", \"nor\", \"else\", \"or\", \"its\", \"it's\", \"of\", \"to\", \"in\", \"on\", \"is\", \"be\",\n",
    "                        \"he\", \"his\", \"him\" \"she\", \"her\", \"an\", \"as\", \"for\", \"by\", \"are\", \"if\", \"it\",\n",
    "                        \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\",\n",
    "                        \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"\n",
    "                      ]\n",
    "\n",
    "    # List to hold results\n",
    "    clean_overview_list = []\n",
    "    for item in overview_list:\n",
    "        # force item to be treated as a string\n",
    "        item =str(item)\n",
    "        \n",
    "        # Split into a list of words\n",
    "        words_list = item.split()\n",
    "        \n",
    "        temp_list = []\n",
    "        # Remove any punctuation\n",
    "        for word in words_list:\n",
    "            # force item to be treated as a string\n",
    "            word = str(word)\n",
    "            word = word.replace(\",\", \"\")\n",
    "            word = word.replace(\".\", \"\")\n",
    "            word = word.replace(\"\\\"\", \"\")\n",
    "            word = word.replace(\"-\", \"\")\n",
    "            word = word.replace(\")\", \"\")\n",
    "            word = word.replace(\"(\", \"\")\n",
    "            temp_list.append(word)\n",
    "        \n",
    "        words_list = temp_list\n",
    "\n",
    "        # Create a new list of filtered words\n",
    "        filtered_words_list = [word for word in words_list if word.lower() not in words_to_remove]\n",
    "        \n",
    "        clean_overview_list.append(filtered_words_list)\n",
    "\n",
    "    return clean_overview_list\n",
    "\n",
    "data[\"genres\"] = clean_genres(data[\"genres\"])\n",
    "data[\"overview\"] = clean_overview(data[\"overview\"])\n",
    "\n",
    "# Print out the first record again\n",
    "print(\"Data after cleaning: \")\n",
    "print(data['title'][0])\n",
    "print(data['genres'][0])\n",
    "print(data['overview'][0], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in overview: 27526\n",
      "Total unique genres in genre: 20 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_unique_words(input_data):\n",
    "    '''\n",
    "        Here we need to find all unique words in the input data.\n",
    "        In this case we will be past a list of words lists.\n",
    "    '''\n",
    "    unique_words = {}\n",
    "    unique_word_index = 0\n",
    "    for word_list in input_data:\n",
    "        for word in word_list:\n",
    "            # First check if dict is not empty\n",
    "            if unique_words:\n",
    "                # Not Empty, so we must check if the current word is in the unique_words dict.\n",
    "                if word not in list(unique_words.values()):\n",
    "                    # Increment the index\n",
    "                    unique_word_index = unique_word_index + 1\n",
    "                    unique_words[unique_word_index] = word\n",
    "            else:\n",
    "                # Empty, add fist item to dict. So index should be {1:'word'}\n",
    "                # Increment the index\n",
    "                unique_word_index = unique_word_index + 1\n",
    "                unique_words[unique_word_index] = word\n",
    "    \n",
    "    # return the unique words dict and the unique word_index value\n",
    "    return unique_words, unique_word_index\n",
    "\n",
    "# Next, we need to figure out how many unique words/genres are in overview and genres\n",
    "unique_words, unique_words_count = find_unique_words(data['overview'])\n",
    "unique_genres, unique_genres_count = find_unique_words(data['genres'])\n",
    "\n",
    "print(\"Total unique words in overview:\", unique_words_count)\n",
    "print(\"Total unique genres in genre:\", unique_genres_count, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First encoded overview item: [11453, 5907, 20345, 20881, 16530, 6804, 14476, 11612, 4003, 17955, 3403, 8024, 24165, 9780, 1714, 9430, 752]\n",
      "First encoded genres item: [1, 15, 16, 16]\n"
     ]
    }
   ],
   "source": [
    "# Our next step is to encode the genres and the overview columns. This should be a bit tricky...\n",
    "# Let's copy our data just in case :)\n",
    "\n",
    "def encode_data(data, size, name):\n",
    "    '''\n",
    "        This function needs to encode (vectorize) a given data set.\n",
    "        It will return the encoded data set.\n",
    "        data is the data we will encode.\n",
    "        size is the number of unique words/items\n",
    "        name is the name of the data inside \"data\".\n",
    "    '''\n",
    "    \n",
    "    encoded_data = []\n",
    "    for item in data[name]:\n",
    "        temp = []\n",
    "        for word in item:\n",
    "            item = one_hot(word, size)\n",
    "            if item:\n",
    "                temp.append(item[0])\n",
    "        encoded_data.append(temp)\n",
    "    \n",
    "    return encoded_data\n",
    "\n",
    "data_copy = deepcopy(data)\n",
    "\n",
    "# Now we encode the data\n",
    "encoded_overview = encode_data(data_copy, unique_words_count, \"overview\")\n",
    "encoded_genres = encode_data(data_copy, unique_genres_count, \"genres\")\n",
    "\n",
    "print(\"First encoded overview item:\", encoded_overview[0])\n",
    "print(\"First encoded genres item:\", encoded_genres[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
