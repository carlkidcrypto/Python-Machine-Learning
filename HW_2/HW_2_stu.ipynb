{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2: Search hyperparameters for neural networks\n",
    "In this homework, you will practice using Keras to implement neural networks and search their hyperparameters for handwritten digits classification.\n",
    "\n",
    "### Dataset\n",
    "MNIST handwritten digits. 60k 28*28 grayscale training images of the 10 digits, along with a test set of 10k images\n",
    "\n",
    "![Fig. 1](handwrittendigits.png)\n",
    " *Fig.1. Handwritten digits examples.* \n",
    "\n",
    "### Instructions\n",
    "\n",
    "    1. You need to install Keras on your computer to build neural networks.\n",
    "    2. The framework, e.g., functions' names, input, and output, has been defined. You are going to complete the create_NN, nn_params_search, retrain_best_nn, myEvaluation functions.\n",
    "    3. Add your code in the following blocks, and do not change other places.\n",
    "\n",
    "```python\n",
    "\n",
    "    ## add your code here\n",
    "    \n",
    "    ##\n",
    "```\n",
    "\n",
    "### Student information\n",
    "    1. Your name: Carlos Santos\n",
    "    2. Department: Comp. E.\n",
    "    3. Undergraduate\n",
    "\n",
    "### Task points and TA grading: ??/100\n",
    "    1. ?/10\n",
    "    2. ?/30\n",
    "    3. ?/30\n",
    "    4. ?/10\n",
    "    5. ?/20\n",
    "    6: performance_acc: ?/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the MNIST dataset in Keras. 10 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_2D: (60000, 28, 28), X_train: (60000, 784)\n",
      "X_test_2D: (10000, 28, 28), X_test: (10000, 784)\n",
      "y_train_onehot: (60000, 10)\n",
      "one-hot vector examples:\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def load_data():\n",
    "    '''Load the MNIST dataset'''\n",
    "    \n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "#Task 1. load the dataset\n",
    "(X_train_2D, y_train, X_test_2D, y_test) = load_data()\n",
    "\n",
    "# 1.1 reshape the training and test sets (N*28*28) to N * 784. 10 points\n",
    "X_train = np.reshape(X_train_2D, (X_train_2D.shape[0], (X_train_2D.shape[1]*X_train_2D.shape[2])))\n",
    "X_test = np.reshape(X_test_2D, (X_test_2D.shape[0], (X_test_2D.shape[1]*X_test_2D.shape[2])))\n",
    "\n",
    "print('X_train_2D: {}, X_train: {}'.format(X_train_2D.shape, X_train.shape))\n",
    "print('X_test_2D: {}, X_test: {}'.format(X_test_2D.shape, X_test.shape))\n",
    "\n",
    "# 1.2 transform y_train to one-hot vectors using keras.utils.to_categorical to form the output of the NN. 10 points\n",
    "y_train_onehot = keras.utils.to_categorical(y_train) \n",
    "print('y_train_onehot: {}'.format(y_train_onehot.shape))\n",
    "print('one-hot vector examples:\\n', y_train_onehot[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create neural networks using Keras. 30 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer: 1 Size of: 1000\n",
      "Hidden Layer: 2 Size of: 500\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 1,290,510\n",
      "Trainable params: 1,290,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_NN(hidden_layers = [1000], act = 'relu', opt = 'rmsprop'): \n",
    "    '''create a deep feedforwad neural network using keras\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    hidden_layers: a list that defines the numbers of hidden nodes for all hidden layers, e.g., [1000] indicates\n",
    "    the nn has only one hidden layer with 1000 nodes, while [1000, 500] defines two hidden layers and the first\n",
    "    layer has 1000 nodes and the second has 500 nodes.\n",
    "    act: activation function for all hidden layers\n",
    "    opt: optimizer\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    myNN: the neural network model\n",
    "    \n",
    "    '''\n",
    "    in_dim = 784\n",
    "    out_dim = 10    \n",
    "    myNN = keras.models.Sequential()\n",
    "    \n",
    "    \n",
    "    num_hidden_layers = 0\n",
    "    for layer in h_nodes:\n",
    "        num_hidden_layers = num_hidden_layers + 1 \n",
    "        print(\"Hidden Layer:\", num_hidden_layers, \"Size of:\", layer)\n",
    "        #2.1 build all hidden layers\n",
    "        myNN.add(keras.layers.Dense(\n",
    "        units=layer,\n",
    "        input_dim=in_dim,\n",
    "        activation=act))\n",
    "\n",
    "    #2.2 build the output layer and use the softmax activation  \n",
    "    myNN.add(keras.layers.Dense(\n",
    "    units=y_train_onehot.shape[1],\n",
    "    input_dim=layer,\n",
    "    activation='softmax'))\n",
    "\n",
    "    #2.3 choose the optimizer, compile the network and return it. Use 'accuracy' as the metrics\n",
    "    myNN.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return myNN\n",
    "    \n",
    "h_nodes = [1000, 500] # two hidden layers with 1000 and 500 nodes, respectively.\n",
    "myNN = create_NN(hidden_layers= h_nodes, act = 'relu', opt = 'adam')\n",
    "myNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Search the best NN paprameters, and report the performance. 30 points\n",
    "    - The KerasClassifier will be used to warp NN models to use the GridSearchCV\n",
    "    - Complete the nn_params_search function to search the three parameters: batch_size, activation, and optimizer.\n",
    "    - Each fit (10 epochs) may take 1 to 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def nn_params_search(nn, X, y, param_grid): # 30 points\n",
    "    '''Search best paramaters\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: features\n",
    "    y_train: target of the input\n",
    "    param_grid: a dict that defines the parameters\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    best_params_\n",
    "        \n",
    "    '''\n",
    "    ## add your code here. set cv = 3, scoring = 'accuracy', and verbose = 2\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##\n",
    "\n",
    "# wrap keras model to use in sklearn\n",
    "nn = KerasClassifier(build_fn = create_NN, batch_size = 64, epochs = 10) # using the keras wapper\n",
    "param_grid = {'batch_size': [64, 128], \n",
    "              'act':['relu', 'sigmoid'], 'opt': ['sgd', 'adam']}\n",
    "\n",
    "best_params = nn_params_search(nn, X_train, y_train, param_grid = param_grid)\n",
    "print('\\nBest parameters: ', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Retrain a neural network using the best parameters. 10 points\n",
    "    - Compelte the retrain_test_nn function to create (create_NN) and train (fit) a new nn using parameters in best_params\n",
    "    - The default epoches are 20 and each epoch may take around 10 to 20 seconds; and you can increase this value to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7ad1eaf78d48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mbestNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretrain_best_nn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_onehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "def retrain_best_nn(best_params, X_train, y_train, epochs = 10): # 10 points\n",
    "    '''Retrain a nn using the best parameters\n",
    "    \n",
    "    Paramters\n",
    "    ----------\n",
    "    best_params:\n",
    "    X_train: data input of the training set\n",
    "    y_train: target of the input (one-hot vectors)\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    bestNN: the nn classifier trained using the best parameters\n",
    "    \n",
    "    '''\n",
    "    ## add your code here  \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##\n",
    "#\n",
    "bestNN = retrain_best_nn(best_params, X_train, y_train_onehot, epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Network evaluation. 20 points\n",
    "\n",
    "    - Complete the myEvaluation function to report the performance of your best nn using the test set\n",
    "        - compute the overall accuracy\n",
    "        - compute the precision for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def myEvaluation(y, y_pred):\n",
    "    ''' calculate the overall accuracy and precision\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        y: real target\n",
    "        y_pred: prediction\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        acc: accuracy\n",
    "        precision: precision array\n",
    "    '''\n",
    "    ## add your code here\n",
    "    # calculate the overall acc\n",
    "\n",
    "    \n",
    "    # calculate the precision for each class\n",
    "\n",
    "    \n",
    "    # return acc and precision array\n",
    "    \n",
    "    \n",
    "    ##\n",
    "\n",
    "#\n",
    "y_test_pred = bestNN.predict_classes(X_test)\n",
    "acc, precision = myEvaluation(y_test, y_test_pred)\n",
    "print('my accuracy:    {:.2f}'.format(acc))\n",
    "print('my precision:', precision)\n",
    "\n",
    "# results calculated using the classification_report\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Any findings or conclusion, e.g., useful strategies to improve nn performance. Extra 10 points\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3.\n",
    "\n",
    "4....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
